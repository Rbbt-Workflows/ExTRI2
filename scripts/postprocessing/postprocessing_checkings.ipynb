{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing of the ExTRI2 pipeline results to create the ExTRI2 resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3>Table of contents</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "[Postprocessing of the ExTRI2 pipeline results to create the ExTRI2 resource](#Postprocessing-of-the-ExTRI2-pipeline-results-to-create-the-ExTRI2-resource)\n",
       "- [Run Main](#Run-Main)\n",
       "- [Setup](#Setup)\n",
       "- [Postprocessing](#Postprocessing)\n",
       "  - [AP1 & NFKB](#AP1-&-NFKB)\n",
       "  - [Discard & Renormalize](#Discard-&-Renormalize)\n",
       "  - [Working on it (move above)](#Working-on-it-(move-above))\n",
       "- [Exploration](#Exploration)\n",
       "  - [Initial exploration](#Initial-exploration)\n",
       "  - [Sentences to check](#Sentences-to-check)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "__import__('sys').path.append('../common/'); __import__('notebook_utils').table_of_contents('postprocessing_checkings.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This notebook will now only be used for the normalisation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### POSTPROCESSING valid_df\n",
      "We got 6696 different TFs and 26108 different TGs from our valid sentences\n",
      "Retrieving from Entrez...\n",
      "\n",
      "4946 sentences are dropped as their TG is not normalised\n",
      "\n",
      "37975 rows (4.23%) will have its TF renormalized to NFKB\n",
      "6287 rows (0.70%) will be dropped as the TG corresponds to NFKB\n",
      "8921 rows (1.00%) will have its TF renormalized to AP1\n",
      "1846 rows (0.21%) will be dropped as the TG corresponds to AP1\n",
      "Breakdown by NCBI Symbol saved in ../../data/postprocessing/tables/AP1_NFKB_breakdown.tsv\n",
      "Number of renormalized sentences and normalization:\n",
      "4787\t0.54%\tp21 is normalized to CDKN1A\n",
      "1906\t0.21%\tp53-ps is normalized to its respective p53 symbol\n",
      "\n",
      "Number of discarded sentences and percentage from total (889384 sentences) and reasoning:\n",
      "2555\t0.29%\tTheir TF contains -AS[1-3]\n",
      "667\t0.07%\tTheir TF are circRNAs\n",
      "945\t0.11%\tTheir TF (NLRP3) is followed by inflammasome but normalised to NLRP3\n",
      "1858\t0.21%\tTheir TG (NLRP3) is followed by inflammasome but normalised to NLRP3\n",
      "82\t0.01%\tThe TG is a fusion gene\n",
      "1081\t0.12%\tTheir TG is followed by pathway/signalling/axis/program\n",
      "2029\t0.23%\tMDM2-TP53 pair, which is always a PPI\n",
      "1063\t0.12%\tTF is CD(4|8A|8B|74|34) positive (indicative of a cell, not a gene)\n",
      "14\t0.00%\tTG is CD(4|8A|8B|74|34) positive (indicative of a cell, not a gene)\n",
      "7349\t0.83%\tThey contain translation in them (found to only be correct 40% of the time)\n",
      "41572\t4.67%\tThey are autoregulations (found to only be correct ~10% of the time)\n",
      "\n",
      "We get ortholog info for 24911/25543 Gene IDs\n",
      "\n",
      "\n",
      "### POSTPROCESSING nonvalid_df\n",
      "We got 4306 different TFs and 10874 different TGs from our valid sentences\n",
      "Retrieving from Entrez...\n",
      "\n",
      "515 sentences are dropped as their TG is not normalised\n",
      "\n",
      "2043 rows (2.76%) will have its TF renormalized to NFKB\n",
      "1190 rows (1.61%) will be dropped as the TG corresponds to NFKB\n",
      "299 rows (0.41%) will have its TF renormalized to AP1\n",
      "253 rows (0.35%) will be dropped as the TG corresponds to AP1\n",
      "Breakdown by NCBI Symbol saved in ../../data/postprocessing/tables/AP1_NFKB_breakdown.tsv\n",
      "Number of renormalized sentences and normalization:\n",
      "110\t0.15%\tp21 is normalized to CDKN1A\n",
      "129\t0.18%\tp53-ps is normalized to its respective p53 symbol\n",
      "\n",
      "Number of discarded sentences and percentage from total (72662 sentences) and reasoning:\n",
      "69\t0.09%\tTheir TF contains -AS[1-3]\n",
      "13\t0.02%\tTheir TF are circRNAs\n",
      "89\t0.12%\tTheir TF (NLRP3) is followed by inflammasome but normalised to NLRP3\n",
      "34\t0.05%\tTheir TG (NLRP3) is followed by inflammasome but normalised to NLRP3\n",
      "19\t0.03%\tThe TG is a fusion gene\n",
      "1552\t2.14%\tTheir TG is followed by pathway/signalling/axis/program\n",
      "87\t0.12%\tMDM2-TP53 pair, which is always a PPI\n",
      "229\t0.32%\tTF is CD(4|8A|8B|74|34) positive (indicative of a cell, not a gene)\n",
      "150\t0.21%\tTG is CD(4|8A|8B|74|34) positive (indicative of a cell, not a gene)\n",
      "588\t0.81%\tThey contain translation in them (found to only be correct 40% of the time)\n",
      "15330\t21.10%\tThey are autoregulations (found to only be correct ~10% of the time)\n",
      "\n",
      "We get ortholog info for 11056/11217 Gene IDs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Self-contained cell to run postprocessing\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "sys.path.append('../../')\n",
    "from scripts.postprocessing.postprocessing import *\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "## Custom functions\n",
    "import sys\n",
    "\n",
    "sys.path.append('../common')\n",
    "sys.path.append('../../')\n",
    "\n",
    "from notebook_utils import table_of_contents, table_from_dict, h3, h4, h5, md, bold\n",
    "from renormalisations import *\n",
    "from postprocessing import *\n",
    "pd.set_option('display.max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkings on the processed final valid df\n",
    "config = load_config()\n",
    "f_valid_df = load_df(config['final_ExTRI2_p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP1 & NFKB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AP1 and NFKB are dimers, and as such don't have neither a NCBI EntrezID, nor a HGNC symbol. PubTator normalizes them to one of their monomers. Therefore, we:\n",
    "* Find all dimers incorrectly normalized to monomers using regex\n",
    "* Change the TF metadata to AP1/NFKB. Delete the TG instances (a TG can't be a dimer)\n",
    "* Show the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST-PROCESSING FUNCTIONS\n",
    "def print_symbol_counts_side_by_side(m_template, max_counts = 10):\n",
    "    'Print symbol counts of m_template for TF & TG'\n",
    "    results = []\n",
    "    for T in ('TF', 'TG'):\n",
    "        m = eval(m_template.replace('{T}', T))\n",
    "        T_lines = valid_df[m][f'{T} Symbol'].value_counts()[:max_counts].to_string().split('\\n')\n",
    "        results.append(T_lines)\n",
    "\n",
    "    # Print the two tables side by side\n",
    "    for tf_line, tg_line in zip(*results):\n",
    "        print(f\"{tf_line:<35} {tg_line}\")\n",
    "\n",
    "def print_dubious_pairs_TFTGcounts_side_by_side(dubious_pairs):\n",
    "    '''Print counts of TF&TG of 3 different symbols side by side'''\n",
    "    all_tables = []\n",
    "    for p in dubious_pairs:\n",
    "        results = []\n",
    "        for T in ('TF', 'TG'):\n",
    "            m = valid_df[f'{T} Symbol'].isin([';'.join((p[0], p[1])), ';'.join((p[1], p[0]))])\n",
    "            T_counts = valid_df[m][f'{T}'].value_counts().rename(f'{T} count')[:10]\n",
    "            results.append(T_counts)\n",
    "\n",
    "        # Merge the TF and TG counts on the same index\n",
    "        merged_df = pd.concat(results, axis=1).fillna(0).astype(int)\n",
    "        all_tables.append(merged_df)\n",
    "\n",
    "    # Convert each table to a string and split by lines\n",
    "    table_strings = [table.to_string().split('\\n') for table in all_tables]\n",
    "\n",
    "    # Use itertools.zip_longest to handle tables with different lengths\n",
    "    for lines in itertools.zip_longest(*table_strings, fillvalue=''):\n",
    "        # Print each line of the three tables side by side\n",
    "        print(f\"{lines[0]:<40} {lines[1]:<40} {lines[2]}\")\n",
    "\n",
    "def print_TF_TG_counts_side_by_side(title, m_template, sep=40):\n",
    "    bold(title)\n",
    "    counts = []\n",
    "    for T in ('TF', 'TG'):\n",
    "        m = eval(m_template)\n",
    "        T_lines = valid_df[m][[f'{T}', f'{T} Symbol']].value_counts().to_string().split('\\n')\n",
    "        counts.append(T_lines)\n",
    "    \n",
    "    for tf_line, tg_line in itertools.zip_longest(*counts, fillvalue=''):\n",
    "        print(f\"{tf_line:<{sep}} {tg_line}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Entities normalized to +1 ID</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "25580 (3%) entities are normalized to more than 1 ID.<br>We revise those that appear more than 100 times further:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Symbol                           TG Symbol\n",
      "MAPK3;MAPK1            5402         MAPK3;MAPK1       1439\n",
      "Mapk3;Mapk1            1676         MMP9;MMP2          398\n",
      "Mapk1;Mapk3            1148         Mapk3;Mapk1        390\n",
      "MAP2K1;MAP2K2           717         SMAD3;SMAD2        251\n",
      "SMAD3;SMAD2             476         Mapk1;Mapk3        228\n",
      "BCR;ABL1                314         CDK4;CDK6          100\n",
      "MAPK9;MAPK8             310         Smad2;Smad3         99\n",
      "FLI1;EWSR1              217         Smad3;Smad2         71\n",
      "Map2k1;Map2k2           213         tat;TAT             68\n",
      "Smad2;Smad3             150         HSD11B1;RNU1-1      66\n",
      "CREBBP;EP300            147         CASP3;CASP7         64\n",
      "PTGDR;OIP5-AS1;OIP5     144         MIR145;MIR143       63\n",
      "SMAD9;SMAD5;SMAD1       127         MAP2K1;MAP2K2       57\n",
      "HDAC2;HDAC1             104         NKX3-1;NKX2-5       54\n",
      "BRCA2;BRCA1              96         Mmp2;Mmp9           50\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "From those, 3 seem suspicious and are investigated further: ABL1;BCR, FLI1;EWSR1, MMP2;MMP9"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TF count  TG count                         TF count  TG count                                                   TF count  TG count\n",
      "BCR/ABL         119         9            EWS-FLI1          137        16          MMP-2/9                                         0        99\n",
      "BCR-ABL1        108        18            EWS/FLI1           43         6          MMP-2/-9                                        0        67\n",
      "BCR/ABL1         34         6            EWS/FLI-1          12        11          MMP2/9                                          0        63\n",
      "Bcr/Abl          26         4            EWS::FLI1           9         2          MMP-2 and -9                                    0        40\n",
      "BCR::ABL1        10         3            EWSR1-FLI1          9         0          matrix metalloproteinase-2 and -9               0        16\n",
      "bcr/abl           8         6            EWSR1::FLI1         7         1          matrix metalloproteinase-2/9                    0        10\n",
      "BCR::ABL          5         0                                                     matrix metalloproteinase-2/-9                   0         9\n",
      "Bcr/abl           3         0                                                     matrix metalloproteinases 2 and 9               0         9\n",
      "BCR/abl           1         0                                                     matrix metalloproteinase (MMP)-2 and -9         0         7\n",
      "                                                                                  matrix metalloproteinase 2 and 9                0         6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Through further manual investigation of the sentences, we have determined that:\n",
       "* FL1;EWSR1 & ABL1;BCR are fusion genes. They are correct TFs but must be discarded as TGs.\n",
       "* TG = MMP9;MMP2 entities indicate that the TF regulates both genes.\n",
       "   \n",
       "One TG sentence example for each case (first two will be discarded)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABL1;BCR:\t These findings suggest that interfere PI3K/[TF] signal pathway via down-regulating the expression of [TG] mRNA is implicated in the effect of 2-ME2 on K562 cells.\n",
      "FLI1;EWSR1:\t These [TF] inhibitors enhanced the mithramycin-mediated suppression of the [TG] transcriptional program leading to a shift in the IC50 and striking regressions of Ewing sarcoma xenografts.\n",
      "MMP2;MMP9:\t Furthermore, the overexpression of [TF] was found to be involved in the inhibition of the metastasis-related proteins [TG], as well as the promotion of the cell-cell adhesion-associated protein E-cadherin.\n"
     ]
    }
   ],
   "source": [
    "### ENTITIES NORMALIZED TO +1 ID\n",
    "bold(\"Entities normalized to +1 ID\")\n",
    "m = (valid_df['TF Symbol'].str.upper().str.contains(';')) | valid_df['TG Symbol'].str.upper().str.contains(';')\n",
    "md(f\"{m.sum()} ({m.sum() / len(m):.0%}) entities are normalized to more than 1 ID.<br>We revise those that appear more than 100 times further:\")\n",
    "m_template = \"valid_df['{T} Symbol'].str.contains(';')\"\n",
    "print_symbol_counts_side_by_side(m_template, max_counts=15)\n",
    "\n",
    "dubious_pairs = [('ABL1', 'BCR'), ('FLI1','EWSR1'), ('MMP2','MMP9')]\n",
    "\n",
    "md(f'From those, 3 seem suspicious and are investigated further: {\", \".join((\";\".join(p) for p in dubious_pairs))}')\n",
    "\n",
    "print_dubious_pairs_TFTGcounts_side_by_side(dubious_pairs)\n",
    "md('''\\\n",
    "Through further manual investigation of the sentences, we have determined that:\n",
    "* FL1;EWSR1 & ABL1;BCR are fusion genes. They are correct TFs but must be discarded as TGs.\n",
    "* TG = MMP9;MMP2 entities indicate that the TF regulates both genes.\n",
    "   \n",
    "One TG sentence example for each case (first two will be discarded)\n",
    "''')\n",
    "\n",
    "for p in dubious_pairs:\n",
    "    pairs = [';'.join(p) for p in itertools.permutations(p)]\n",
    "    print(f\"{pairs[0]}:\\t\", valid_df[valid_df['TG Symbol'].isin(pairs)].sample(1)['Sentence'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_to_check_path = config['data_p'] + 'validation/sents_to_check.tsv'\n",
    "sents_to_check_2_path = config['data_p'] + 'validation/sents_to_check_2.tsv'\n",
    "sents_to_check_of_path = config['data_p'] + 'validation/sents_to_check_of.tsv'\n",
    "sents_to_check_CDX_path = config['data_p'] + 'validation/sents_to_check_CDX.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Sentences with 'p21' not normalised to 'CDKN1A':</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF   TF Symbol                           TG   TG Symbol\n",
      "p21  Tceal1       14                     p21  H3P16        4471\n",
      "     TCEAL1        1                          Kras          230\n",
      "                                              TCEAL1         30\n",
      "                                              Tceal1         25\n",
      "                                              Tpt1            1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Sentences with 'p53' not normalised to 'TP53':</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF   TF Symbol                           TG   TG Symbol\n",
      "p53  Trp53        193                    p53  Trp53-ps     1595\n",
      "                                              p53-ps        240\n",
      "                                              Trp53          87\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Sentences with MDM2-TP53 pairs must be removed: they're always a PPI. <span style='color: red'>Discard after ^ is fixed</span></b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Symbol  TG Symbol\n",
      "MDM2       TP53         1601\n",
      "Mdm2       TP53           23\n",
      "MDM4;MDM2  TP53            3\n",
      "MDM2       TP53BP2         1 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Sentences with 'MET' not normalised to 'MET':</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF   TF Symbol                           TG   TG Symbol\n",
      "MET  SLTM         483                    MET  SLTM         389\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Sentences with 'CD\\d' :</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF            TF Symbol                  TG             TG Symbol\n",
      "CD34          CD34         1691          CD34           CD34         205\n",
      "              Cd34          113          CD4            CD4          162\n",
      "CD34(         Cd34            5                         Cd4           82\n",
      "              CD34            2          Cd4            CD4           46\n",
      "cd34          CD34            2          CD34           Cd34          40\n",
      "CD4CD25FoxP3  FOXP3           2          CD74           CD74          27\n",
      "CD34+         CD34            1          CD8alpha       Cd8a          17\n",
      "CD34LC        CD34            1          Cd4            Cd4           12\n",
      "CD34Exo       CD34            1          Cd74           Cd74           9\n",
      "CD4.Ezh2      Cd4;Ezh2        1          CD74           Cd74           8\n",
      "CD34brCD38    CD34;CD38       1          Cd8a           CD8A           5\n",
      "                                         CD8a           Cd8a           5\n",
      "                                         CD8alpha       CD8A           4\n",
      "                                         CD8A           CD8A           3\n",
      "                                         CD8B           CD8B           2\n",
      "                                         CD8beta        CD8B           2\n",
      "                                         CD34EGFP       Cd34           1\n",
      "                                         CD34 antigen   CD34           1\n",
      "                                         CD4 receptor   CD4            1\n",
      "                                         CD4;IFN-gamma  Cd4;Ifng       1\n",
      "                                         CD8b           Cd8b1          1\n",
      "                                         CD8a           CD8A           1\n",
      "                                         Cd34           CD34           1\n",
      "                                                        Cd34           1\n",
      "                                         Cd74           CD74           1\n",
      "                                         Cd8alpha       CD8A           1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Entities normalised to +1 IDs: ABL1;BCR</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], )                             Series([], )\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Autoregulation:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.8% of sentences show autoregulation: TF & TG are the same. Most popular:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Symbol  TG Symbol\n",
      "TP53       TP53         1962\n",
      "VEGFA      VEGFA        1104\n",
      "EGFR       EGFR          834\n",
      "ERBB2      ERBB2         710\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Translation instead of gene expression</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7391 sentences contain 'translat' in them and should be checked\n"
     ]
    }
   ],
   "source": [
    "# PREPARE SENTECES TO CHECK\n",
    "def add_to_sents_to_check(sents_to_check: list, m_template: str, issue: str) -> list:\n",
    "    T = 'TF'\n",
    "    m = eval(m_template)\n",
    "    T = 'TG'\n",
    "    m |= eval(m_template)\n",
    "    df_m = valid_df[m].copy()\n",
    "    df_m['issue'] = issue\n",
    "    sents_to_check.append(df_m)\n",
    "\n",
    "sents_to_check = []\n",
    "\n",
    "t = \"Sentences with 'p21' not normalised to 'CDKN1A':\"\n",
    "m_template = \"(valid_df[f'{T}'] == 'p21') & (valid_df[f'{T} Symbol'].str.upper() != 'CDKN1A')\"\n",
    "print_TF_TG_counts_side_by_side(t, m_template)\n",
    "add_to_sents_to_check(sents_to_check, m_template, 'p21-CDKN1A')\n",
    "\n",
    "\n",
    "t = \"Sentences with 'p53' not normalised to 'TP53':\"\n",
    "m_template = \"(valid_df[f'{T}'] == 'p53') & (valid_df[f'{T} Symbol'].str.upper() != 'TP53')\"\n",
    "print_TF_TG_counts_side_by_side(t, m_template)\n",
    "add_to_sents_to_check(sents_to_check, m_template, 'p53-TP53')\n",
    "\n",
    "bold(f\"Sentences with MDM2-TP53 pairs must be removed: they're always a PPI.\")\n",
    "m = valid_df['TF Symbol'].str.upper().str.contains('MDM2')\n",
    "m &= valid_df['TG Symbol'].str.upper().str.contains('TP53')\n",
    "print(valid_df[m][['TF Symbol', 'TG Symbol']].value_counts().to_string(), '\\n')\n",
    "\n",
    "\n",
    "t = \"Sentences with 'MET' not normalised to 'MET':\"\n",
    "m_template = \"(valid_df[f'{T}'] == 'MET') & (valid_df[f'{T} Symbol'].str.upper() != 'MET')\"\n",
    "print_TF_TG_counts_side_by_side(t, m_template)\n",
    "add_to_sents_to_check(sents_to_check, m_template, 'MET')\n",
    "\n",
    "\n",
    "t = \"Sentences with 'CD\\d' :\"\n",
    "m_template = \"valid_df[f'{T}'].str.upper().str.contains(r'^CD(?:4|8A|8B|74|34)(?!\\d)')\"\n",
    "print_TF_TG_counts_side_by_side(t, m_template)\n",
    "add_to_sents_to_check(sents_to_check, m_template, 'CD*')\n",
    "\n",
    "# Joined NCBI IDs to check\n",
    "t = \"Entities normalised to +1 IDs: ABL1;BCR\"\n",
    "m_template = \"valid_df[f'{T} Symbol'] == 'ABL1;BCR'\"\n",
    "print_TF_TG_counts_side_by_side(t, m_template)\n",
    "add_to_sents_to_check(sents_to_check, m_template, 'ABL1;BCR')\n",
    "\n",
    "\n",
    "bold(f\"\\nAutoregulation:\")\n",
    "m = valid_df['TF Symbol'].str.upper() == valid_df['TG Symbol'].str.upper()\n",
    "md(f\"{m.sum() / len(valid_df):.1%} of sentences show autoregulation: TF & TG are the same. Most popular:\")\n",
    "print(valid_df[m][['TF Symbol', 'TG Symbol']].value_counts()[:4].to_string())\n",
    "\n",
    "# Those are potentially commonly wrong. Prepare a set of 300 sentences for validation purposes\n",
    "df_m = valid_df[m].sample(n=300)\n",
    "df_m['issue'] = 'Autoregulation'\n",
    "sents_to_check.append(df_m)\n",
    "\n",
    "bold('\\nTranslation instead of gene expression')\n",
    "m = valid_df['Sentence'].str.lower().str.contains('translat')\n",
    "print(f\"{m.sum()} sentences contain 'translat' in them and should be checked\")\n",
    "df_m = valid_df[m].sample(n=100)\n",
    "df_m['issue'] = 'Translate'\n",
    "sents_to_check.append(df_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE EXCEL\n",
    "def extract_context(sentence, token='[TF]', window=4, how='both'):\n",
    "    '''Get the last and next 4 words from the token'''\n",
    "    # Split the sentence by spaces\n",
    "    words = sentence.split()\n",
    "\n",
    "    # Find the index of the word that contains '[TF]' or its variations\n",
    "    index = [i for i, word in enumerate(words) if token in word][0]\n",
    "\n",
    "    # Extract the 4 words before and after the token, handling boundaries\n",
    "    start = max(0, index) if how=='right' else max(0, index - window)\n",
    "    end = min(len(words), index + 1) if how=='left' else min(len(words), index + window + 1)\n",
    "\n",
    "\n",
    "    # Join the extracted context words back into a string\n",
    "    return ' '.join(['...'] + words[start:end] + ['...'])\n",
    "\n",
    "sents_to_check = pd.concat(sents_to_check)\n",
    "\n",
    "cols_to_keep = ['issue', 'TF', 'TF Symbol', 'TG', 'TG Symbol', 'Sentence',  '#SentenceID', \n",
    "                'TF Id', 'TG Id', 'MoR', 'TF TaxID',  'TG TaxID', 'TF_type', 'TF Species',\n",
    "                'TG Species', 'issue']\n",
    "\n",
    "sents_to_check = sents_to_check[cols_to_keep]\n",
    "\n",
    "for T in ('TF', 'TG'):\n",
    "    sents_to_check[f'{T}_context'] = sents_to_check['Sentence'].apply(lambda x: extract_context(x, token=f'{T}'))\n",
    "    sents_to_check[f'{T}_left_context'] = sents_to_check['Sentence'].apply(lambda x: extract_context(x, token=f'{T}', how='left'))\n",
    "    sents_to_check[f'{T}_right_context'] = sents_to_check['Sentence'].apply(lambda x: extract_context(x, token=f'{T}', how='right'))\n",
    "\n",
    "sents_to_check.to_csv(sents_to_check_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "dbTF Autoregulation:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2.2% of sentences show autoregulation: TF & TG are the same. Most popular:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Symbol  TG Symbol\n",
      "TP53       TP53         1962\n",
      "MYC        MYC           710\n",
      "HIF1A      HIF1A         464\n",
      "ESR1       ESR1          434\n",
      "results saved in ../../data/validation/sents_to_check_2.tsv\n"
     ]
    }
   ],
   "source": [
    "# PREPARE 2nd SET OF SENTENCES TO CHECK\n",
    "bold(f\"\\ndbTF Autoregulation:\")\n",
    "\n",
    "# Get a set of 300 sentences to check with autoregulation (dbTF)#\n",
    "# Previous set contained a lot of coTF sentences. We want to check the number of false positives in dbTF-specific autoregulation.\n",
    "m = f_valid_df['TF Symbol'].str.upper() == f_valid_df['TG Symbol'].str.upper()\n",
    "m &= f_valid_df['TF_type'] == 'dbTF'\n",
    "md(f\"{m.sum() / len(f_valid_df):.1%} of sentences show autoregulation: TF & TG are the same. Most popular:\")\n",
    "print(f_valid_df[m][['TF Symbol', 'TG Symbol']].value_counts()[:4].to_string())\n",
    "df_m = f_valid_df[m].sample(n=300)\n",
    "df_m['issue'] = 'dbTF_autoregulation'\n",
    "\n",
    "# We will only check dbTF autoregulation\n",
    "sents_to_check_2 = df_m\n",
    "tab_cols = (\"issue\t#SentenceID\tTF\tTF Symbol\tTG\tTG Symbol\tSentence\tTF Id\tTG Id\tTF offset\tGene offset\tMutated Genes\tMutation offsets\tValid score\tValid\tMoR scores\tMoR\tPMID\tPMID+Sent+TRI_Id\tMutated_TF\tTF TaxID\tTG TaxID\tTF_type\tTF_human_entrez_gene\tTF_hgnc_id\tTF_human_symbol\tTG_human_entrez_gene\tTG_hgnc_id\tTG_human_symbol\tTG_human_entrez_gene\tTG_hgnc_id\tTG_human_symbol\")\n",
    "sents_to_check_2 = sents_to_check_2[tab_cols.split(\"\\t\")]\n",
    "\n",
    "sents_to_check_2.to_csv(sents_to_check_2_path, sep='\\t', index=False)\n",
    "print(f\"results saved in {sents_to_check_2_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TG     TG Symbol\n",
       "CD44   CD44         933\n",
       "CD133  PROM1        349\n",
       "CD40   CD40         306\n",
       "CD86   CD86         235\n",
       "       Cd86         179\n",
       "                   ... \n",
       "cd274  Cd274          1\n",
       "CD101  CD101          1\n",
       "CD1    Cd1d1          1\n",
       "cd5    CD5            1\n",
       "cd59   CD59           1\n",
       "Name: count, Length: 489, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.int64(9317)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPARE 3rd SET OF SENTENCES TO CHECK\n",
    "m = f_valid_df['TG'] == 'of'\n",
    "m |= f_valid_df['TF'] == 'of'\n",
    "sents_to_check_of = f_valid_df[m].sort_values(by=['TF', 'TG'])\n",
    "sents_to_check_of.to_csv(sents_to_check_of_path, sep='\\t', index=False)\n",
    "\n",
    "m = f_valid_df['TG'].str.upper().str.contains(\"^CD[0-9]\")\n",
    "m &= f_valid_df['Sentence'].str.contains(\"\\[TG\\] ?\")\n",
    "\n",
    "display(f_valid_df[m][['TG', 'TG Symbol']].value_counts())\n",
    "m.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = f_valid_df['TG'].str.upper().str.contains(\"^CD[0-9]\")\n",
    "f_valid_df[m].to_csv(sents_to_check_CDX_path, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
