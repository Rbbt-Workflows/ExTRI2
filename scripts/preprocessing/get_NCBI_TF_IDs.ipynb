{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of TF NCBI IDs \n",
    "Get the list of IDs that will be considered TF, both from GO terms and from TFCheckpoint.\n",
    "\n",
    "The GO terms and columns from TFCheckpoint used for each of the TF types is detailed in the cell below. The specific procedure used is explained in their respective sections:  [Get GO terms](#get-go-terms) and [GET TFCheckpoint terms](#get-tfcheckpoint-terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3>Table of contents</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "[Get List of TF NCBI IDs](#Get-List-of-TF-NCBI-IDs)\n",
       "- [Setup](#Setup)\n",
       "- [Get GO terms](#Get-GO-terms)\n",
       "- [Get TFCheckpoint terms](#Get-TFCheckpoint-terms)\n",
       "- [Get final TF set for the pipeline](#Get-final-TF-set-for-the-pipeline)\n",
       "- [Create final TF table](#Create-final-TF-table)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "__import__('sys').path.append('../common/'); __import__('notebook_utils').table_of_contents('get_NCBI_TF_IDs.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import difflib\n",
    "\n",
    "from Bio import Entrez\n",
    "# *Always* tell NCBI who you are\n",
    "Entrez.email = \"example24@gmail.com\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "from notebook_utils import h3, h4, h5, md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL FUNCTIONS\n",
    "def retrieve_annotations_entrez(id_list):\n",
    "    \"\"\"Annotates Entrez Gene IDs using Bio.Entrez, in particular epost (to\n",
    "    submit the data to NCBI) and esummary to retrieve the information.\n",
    "    Returns a list of dictionaries with the annotations.\"\"\"\n",
    "\n",
    "    request = Entrez.epost(\"gene\", id=\",\".join(id_list))\n",
    "    result = Entrez.read(request)\n",
    "    webEnv = result[\"WebEnv\"]\n",
    "    queryKey = result[\"QueryKey\"]\n",
    "    data = Entrez.esummary(db=\"gene\", webenv=webEnv, query_key=queryKey)\n",
    "    annotations = Entrez.read(data)\n",
    "    annotationsSummary = annotations['DocumentSummarySet']['DocumentSummary']\n",
    "\n",
    "    assert len(id_list) == len(annotationsSummary), f\"id_list and annotationsSummary are of different length: {len(id_list)} != {len(annotationsSummary)}\"\n",
    "\n",
    "    return annotationsSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO TERM & TFCHECKPOINT VARIABLES\n",
    "\n",
    "# GO terms used:\n",
    "GO_dbTF = [\"GO:0003700\"]\n",
    "GO_coTF = [\"GO:0003712\", \"GO:0001098\", \"GO:0002039\" , \"GO:0008134\" , \"GO:0042393\", \"GO:0046332\", \"GO:0006325\", \"GO:0140993\"]\n",
    "\n",
    "# Columns from TFCheckpoint used:\n",
    "TFCheckpoint_cols = {\n",
    "    'dbTF': ['TFclass.present.merged', 'lambert_2018.present', 'Lovering_2021.present'],\n",
    "    'coTF': ['animal_tfdb_Homo_sapiens_cofactors.present', 'animal_tfdb_Mus_musculus_cofactors.present', 'animal_tfdb_Rattus_norvegicus_cofactors.present', \n",
    "             'tcof_cotf_human.present', 'tcof_cotf_mouse.present']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "external_data_path = '../../data/external/TF_id/'\n",
    "postprocessing_path = '../../data/postprocessing/'\n",
    "paper_tables_path = '../../data/paper_tables/'\n",
    "\n",
    "# External data\n",
    "QuickGO_dbTF_path = external_data_path + \"QuickGO-annotations-dbTF.tsv\"\n",
    "QuickGO_coTF_path = external_data_path + \"QuickGO-annotations-coTF.tsv\"\n",
    "TFCheckpoint_path = external_data_path + \"TFCheckpoint.tsv\"\n",
    "\n",
    "# From postprocessing\n",
    "less_likely_coTFs_path = postprocessing_path + 'all_coTFs_likely_checked_updated_AL.txt'\n",
    "all_orthologs_path     = postprocessing_path + 'tables/orthologs_final.tsv'\n",
    "\n",
    "# Define a function to construct the TF types path\n",
    "def get_TF_ids_path(TF_type, out_data_path):\n",
    "    return f\"{out_data_path}{TF_type}_entrez_code.list\"\n",
    "\n",
    "# All considered TFs are saved in analysis\n",
    "all_TFs_path            = '../../analysis/tables/all_TFs.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LIKELY & LESS LIKELY COTFs\n",
    "ll_coTFs_db = pd.read_csv(less_likely_coTFs_path, sep=\"\\t\", dtype='str')\n",
    "m = ll_coTFs_db['likely'] == 'likely'\n",
    "ll_coTF = set(ll_coTFs_db[~m]['NCBI ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GO terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Obtained the GO terms from [QuickGO](https://www.ebi.ac.uk/QuickGO/annotations?taxonId=10116,9606,10090&taxonUsage=exact&goId=GO:0140993,GO:0003712,GO:0003700,GO:0140223,GO:0001098,GO:0002039,GO:0008134,GO:0042393,GO:0046332,GO:0006325&goUsageRelationships=is_a,part_of,occurs_in&goUsage=descendants&geneProductSubset=Swiss-Prot&geneProductType=protein), using the terms shown below. Used as filters:\n",
    "\n",
    "* **Taxon:** 10116, 9606, 10090, Exact match (do not include descendants)\n",
    "* **Gene products:** Reviewed (not Unreviewed)\n",
    "* **GO terms:**.\n",
    "  * **dbTF:** GO:0003700 (DNA-binding transcription factor activity)\n",
    "  * **coTF:** GO:0140993 (histone modifying activity), GO:0008134 (transcription factor binding), GO:0003712 (transcription coregulator activity), GO:0001098 (basal transcription machinery binding), GO:0002039 (p53 binding), GO:0042393 (histone binding), GO:0046332 (SMAD binding) and GO:0006325 (chromatin organization)\n",
    "* **Export as:** tsv\n",
    "\n",
    "Downloaded separately a QuickGO tsv file for each TF type and renamed it as shown above in the setup section.\n",
    "\n",
    "As some terms can be identified as pertaining to more than 1 type, we have followed this hierarchy to remove duplicates:\n",
    "1. dbTF\n",
    "2. coTF\n",
    "\n",
    "That implies that if a protein is classified as both dbTF and coTF, the protein's classification will be dbTF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25053 rows were retrieved from QuickGO.\n",
      "Removing duplicates, we retrieve 6005 symbols:\n",
      "\t2184 dbTFs\n",
      "\t3156 coTFs\n"
     ]
    }
   ],
   "source": [
    "# JOIN QUICKGO TSVs\n",
    "# Create joined DataFrame from the 3 TF types\n",
    "QuickGO_dbTF = pd.read_csv(QuickGO_dbTF_path, sep='\\t', header=0, keep_default_na=False, dtype='str')\n",
    "QuickGO_coTF = pd.read_csv(QuickGO_coTF_path, sep='\\t', header=0, keep_default_na=False, dtype='str')\n",
    "\n",
    "QuickGO_dbTF['TF type'] = 'dbTF'\n",
    "QuickGO_coTF['TF type'] = 'coTF' \n",
    "\n",
    "QuickGO = pd.concat([QuickGO_dbTF, QuickGO_coTF], axis=0)\n",
    "\n",
    "print(f\"{len(QuickGO['SYMBOL'])} rows were retrieved from QuickGO.\")\n",
    "\n",
    "# Only keep relevant columns\n",
    "QuickGO = QuickGO[['SYMBOL', 'TAXON ID', 'TF type', 'GO TERM']]\n",
    "\n",
    "# Drop repeated cells. Use the following priority if duplicates of different TF type\n",
    "priority = {'dbTF': 0, 'coTF': 1}\n",
    "QuickGO['priority'] = QuickGO['TF type'].map(priority)\n",
    "QuickGO = QuickGO.sort_values(by=['SYMBOL', 'TAXON ID', 'priority'])\n",
    "QuickGO = QuickGO.drop_duplicates(subset=['SYMBOL', 'TAXON ID', 'GO TERM'], keep='first')\n",
    "QuickGO = (\n",
    "    QuickGO\n",
    "    .groupby([\"SYMBOL\", \"TAXON ID\"], as_index=False)\n",
    "    .agg({\n",
    "        'TF type': lambda x: \";\".join(sorted(set(x.astype(str)))),\n",
    "        'GO TERM': 'first'   # take top-priority GO TERM\n",
    "    })\n",
    ")\n",
    "\n",
    "# Show results\n",
    "print(f\"Removing duplicates, we retrieve {len(QuickGO['SYMBOL'])} symbols:\")\n",
    "for TF_type in ('dbTF', 'coTF'):\n",
    "    print(f\"\\t{len(QuickGO[QuickGO['TF type'] == TF_type]['SYMBOL'])} {TF_type}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GProfiler retrieved 98.2% NCBI Gene IDs from the QuickGO symbols\n",
      "It couldn't retrieve 108 of them\n"
     ]
    }
   ],
   "source": [
    "# RETRIEVE GENE IDs FROM GPROFILER\n",
    "def fetch_gene_ids_gprofiler(gene_symbols: list, organism: str) -> dict:\n",
    "    \"Get NCBI Gene IDs from GProfiler\"\n",
    "    symboltoID = {}\n",
    "\n",
    "    # Query the IDs from GProfiler\n",
    "    result = requests.post(\n",
    "        url='https://biit.cs.ut.ee/gprofiler/api/convert/convert/',\n",
    "        json={\n",
    "            'organism': organism,\n",
    "            'target':'ENTREZGENE_ACC',\n",
    "            'query': gene_symbols,\n",
    "        }\n",
    "        )\n",
    "    \n",
    "    # Create a list of extracted IDs per symbol\n",
    "    for r in result.json()['result']:\n",
    "        incoming = r['incoming']\n",
    "        converted = r['converted']\n",
    "\n",
    "        if incoming not in symboltoID:\n",
    "            symboltoID[incoming] = []\n",
    "        if converted != 'None':\n",
    "            symboltoID[incoming].append(converted)\n",
    "\n",
    "    return symboltoID\n",
    "\n",
    "organismToTaxID = {\n",
    "    \"hsapiens\": \"9606\",\n",
    "    \"mmusculus\": \"10090\",\n",
    "    \"rnorvegicus\": \"10116\"}\n",
    "\n",
    "for organism in ['hsapiens', 'mmusculus', 'rnorvegicus']:\n",
    "    # Get IDs from GProfiler\n",
    "    symbols = list(QuickGO[QuickGO['TAXON ID'] == organismToTaxID[organism]]['SYMBOL'].unique())\n",
    "    symboltoID = fetch_gene_ids_gprofiler(symbols, organism)\n",
    "\n",
    "    # Map them to QuickGO db\n",
    "    m = QuickGO['TAXON ID'] == organismToTaxID[organism]\n",
    "    QuickGO.loc[m, \"TF ID\"] = QuickGO[m]['SYMBOL'].apply(lambda symbol: symboltoID[symbol])\n",
    "\n",
    "m = ~(QuickGO['TF ID'].str.len() == 0)\n",
    "print(f'GProfiler retrieved {m.sum() / len(QuickGO):.1%} NCBI Gene IDs from the QuickGO symbols')\n",
    "print(f\"It couldn't retrieve {(~m).sum()} of them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve the rest through a query to Entrez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9606\n",
      "9606\n",
      "9606\n",
      "10090\n",
      "10090\n",
      "10116\n",
      "10116\n",
      "10116\n",
      "10116\n",
      "79 out of the remaining 108 missing have been retrieved through Entrez.\n",
      "Combined with Entrez, we retrieved 99.4% NCBI Gene IDs from the QuickGO symbols\n",
      "There's 35 NCBI Gene IDs that couldn't be retrieved\n"
     ]
    }
   ],
   "source": [
    "# QUERY THE REST FROM ENTREZ\n",
    "# Get IDs from Entrez\n",
    "ids = []\n",
    "for TaxID in ['9606', '10090', '10116']:\n",
    "\n",
    "    # Get the symbols with missing ID\n",
    "    m = (QuickGO['TF ID'].str.len() == 0) & (QuickGO['TAXON ID'] == TaxID)\n",
    "    missing_symbols = list(QuickGO[m]['SYMBOL'].unique())\n",
    "\n",
    "    nSymbols = 15 # Symbols per query\n",
    "    for i in range(0, len(missing_symbols), nSymbols):\n",
    "        symbols = missing_symbols[i:i+nSymbols]\n",
    "        # Query them from Entrez\n",
    "        symbolsQuery = sorted([s+'[Preferred Symbol]' for s in symbols])\n",
    "        query = f'({\" OR \".join(symbolsQuery)}) AND txid{TaxID}[Organism]'\n",
    "        handle = Entrez.esearch(db=\"gene\", term=query, retmode=\"xml\")\n",
    "        record = Entrez.read(handle)\n",
    "        ids.append(record.get(\"IdList\", []))\n",
    "        print(TaxID)\n",
    "        # Sleep between queries to not get blocked\n",
    "        time.sleep(5)\n",
    "\n",
    "# Map IDs back to its symbol & organism\n",
    "all_ids = [j for i in ids for j in i]\n",
    "remaining_annotations = retrieve_annotations_entrez(all_ids)\n",
    "\n",
    "# Make a map from symbol/TaxID to Gene ID\n",
    "symboltoID_entrez = {'9606': {}, '10116': {}, '10090': {}}\n",
    "for id, ann in zip(all_ids, remaining_annotations):\n",
    "    symbol = ann['Name']\n",
    "    TaxID = ann['Organism']['TaxID']\n",
    "\n",
    "    if symbol not in symboltoID_entrez[TaxID]:\n",
    "        symboltoID_entrez[TaxID][symbol] = [id]\n",
    "    else:\n",
    "        symboltoID_entrez[TaxID][symbol].append(id)\n",
    "\n",
    "# Check how many we retrieved from Entrez\n",
    "m = (QuickGO['TF ID'].str.len() == 0)\n",
    "print(f\"{len(all_ids)} out of the remaining {m.sum()} missing have been retrieved through Entrez.\")\n",
    "\n",
    "# Map the retrieved ones to the QuickGO db\n",
    "for TaxID in symboltoID_entrez.keys():\n",
    "    m = (QuickGO['TF ID'].str.len() == 0) & (QuickGO['TAXON ID'] == TaxID)\n",
    "    QuickGO.loc[m, \"TF ID\"] = QuickGO[m]['SYMBOL'].apply(lambda symbol: symboltoID_entrez[TaxID].get(symbol, []))\n",
    "\n",
    "m = ~(QuickGO['TF ID'].str.len() == 0)\n",
    "print(f'Combined with Entrez, we retrieved {m.sum() / len(QuickGO):.1%} NCBI Gene IDs from the QuickGO symbols')\n",
    "print(f\"There's {(~m).sum()} NCBI Gene IDs that couldn't be retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Get TFCheckpoint terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4>EntrezIDs mapped to 2 species</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "There are 5 Entrez IDs that are mapped to both Rat and Mouse:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>EntrezIDs</th>\n",
       "      <th>Associated.Gene.Name</th>\n",
       "      <th>TaxaIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20851</td>\n",
       "      <td>STAT5A</td>\n",
       "      <td>10116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20851</td>\n",
       "      <td>STAT5B</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22764</td>\n",
       "      <td>ZFX</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22764</td>\n",
       "      <td>ZFY</td>\n",
       "      <td>10116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24918</td>\n",
       "      <td>STAT5A</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24918</td>\n",
       "      <td>STAT5B</td>\n",
       "      <td>10116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25126</td>\n",
       "      <td>STAT5A</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25126</td>\n",
       "      <td>STAT5B</td>\n",
       "      <td>10116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367832</td>\n",
       "      <td>ZFX</td>\n",
       "      <td>10116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367832</td>\n",
       "      <td>ZFY</td>\n",
       "      <td>10090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "They have been searched in the NCBI and corrected manually"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD & PREPROCESS TFCHECKPOINT TSV\n",
    "# Load TFCheckpoint dataset\n",
    "TFCheckpoint_df = pd.read_csv(TFCheckpoint_path, sep='\\t', header=0)\n",
    "str_cols = ['Associated.Gene.Name', 'Synonyms', 'Official name', 'Entrez.Taxa.ID', 'Entrez.Gene.ID', 'UniProt.SwissProt.Accession', 'Ensembl.Gene.ID']\n",
    "TFCheckpoint_df[str_cols] = TFCheckpoint_df[str_cols].astype(str)\n",
    "\n",
    "# Split Entrez, Taxa & UniProt into individual IDs\n",
    "TFCheckpoint_df['EntrezIDs'] = TFCheckpoint_df['Entrez.Gene.ID'].str.split('|')\n",
    "TFCheckpoint_df['TaxaIDs']   = TFCheckpoint_df['Entrez.Taxa.ID'].str.split('|')\n",
    "TFCheckpoint_df['UniProt']   = TFCheckpoint_df['UniProt.SwissProt.Accession'].str.split('|')\n",
    "TFCheckpoint_df['Ensembl']   = TFCheckpoint_df['Ensembl.Gene.ID'].str.split('|')\n",
    "\n",
    "# Explode the TF\n",
    "TFCheckpoint_exploded = TFCheckpoint_df.explode(['EntrezIDs', 'TaxaIDs', 'UniProt', 'Ensembl'])\n",
    "# Drop empty rows (Appeared when | was present at the end, e.g. \"9454|3425|\")\n",
    "TFCheckpoint_exploded = TFCheckpoint_exploded[(\n",
    "    (TFCheckpoint_exploded[\"EntrezIDs\"] != '') &\n",
    "    (TFCheckpoint_exploded[\"UniProt\"] != '') &\n",
    "    (TFCheckpoint_exploded[\"Ensembl\"] != '')\n",
    ")] \n",
    "\n",
    "# Check whether each EntrezID only matches to 1 TaxaID:\n",
    "gene_taxa_unique = TFCheckpoint_exploded.drop_duplicates(subset=[\"EntrezIDs\", \"TaxaIDs\"], keep='first')\n",
    "gene_taxa_mismatch = gene_taxa_unique[gene_taxa_unique.duplicated(subset=[\"EntrezIDs\"], keep=False)]\n",
    "h4(\"EntrezIDs mapped to 2 species\")\n",
    "md(f\"There are {len(gene_taxa_mismatch['EntrezIDs'].unique())} Entrez IDs that are mapped to both Rat and Mouse:\")\n",
    "display(HTML(gene_taxa_mismatch[[\"EntrezIDs\", \"Associated.Gene.Name\", \"TaxaIDs\"]].sort_values(by=['EntrezIDs']).to_html(index=False)))\n",
    "\n",
    "# MANUALLY DROP MISMATCHING ROWS\n",
    "rows_to_drop = [\n",
    "    ['STAT5A', '20851', '10116'],\n",
    "    ['STAT5A', '25126', '10090'],\n",
    "    ['ZFY', '367832', '10090'],\n",
    "    ['ZFY', '22764', '10116'],\n",
    "    ['STAT5B', '24918', '10116']\n",
    "]\n",
    "for row in rows_to_drop:\n",
    "    to_drop = (TFCheckpoint_exploded[\"Associated.Gene.Name\"] == row[0]) & (TFCheckpoint_exploded[\"EntrezIDs\"] == row[1])\n",
    "    assert to_drop.sum() == 1, f\"{to_drop.sum()} rows are being dropped instead of 1\"\n",
    "    TFCheckpoint_exploded = TFCheckpoint_exploded[~to_drop]\n",
    "to_change = (TFCheckpoint_exploded[\"Associated.Gene.Name\"] == \"STAT5A\") & (TFCheckpoint_exploded[\"EntrezIDs\"] == \"24918\")\n",
    "assert to_change.sum() == 1, f\"{to_change.sum()} rows are being dropped instead of 1\"\n",
    "TFCheckpoint_exploded.loc[to_change, \"TaxaIDs\"] = \"10116\"\n",
    "md(\"They have been searched in the NCBI and corrected manually\")\n",
    "\n",
    "# Assert there's no duplicates anymore\n",
    "gene_taxa_unique = TFCheckpoint_exploded.drop_duplicates(subset=[\"EntrezIDs\", \"TaxaIDs\"], keep='first')\n",
    "gene_taxa_mismatch = gene_taxa_unique[gene_taxa_unique.duplicated(subset=[\"EntrezIDs\"], keep=False)]\n",
    "assert len(gene_taxa_mismatch) == 0, f\"There's still {len(gene_taxa_mismatch)} duplicated rows\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In 16 TFs, one EntrezID is mapped to 2 different SwissProt Accession IDs. They have been joined by |. Example:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Associated.Gene.Name</th>\n",
       "      <th>Official name</th>\n",
       "      <th>EntrezIDs</th>\n",
       "      <th>TaxaIDs</th>\n",
       "      <th>UniProt</th>\n",
       "      <th>Ensembl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ABL1</td>\n",
       "      <td>Tyrosine-protein kinase ABL1</td>\n",
       "      <td>100909750</td>\n",
       "      <td>10116</td>\n",
       "      <td>E9PT20|F1M0A6</td>\n",
       "      <td>ENSRNOG00000009371|ENSRNOG00000009371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CHCHD2</td>\n",
       "      <td>Coiled-coil-helix-coiled-coil-helix domain-containing protein 2</td>\n",
       "      <td>316643</td>\n",
       "      <td>10116</td>\n",
       "      <td>Q5BJB3|M0R785</td>\n",
       "      <td>ENSRNOG00000051180|ENSRNOG00000051180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GROUP DUPLICATED ROWS & GET FINAL TFCHECKPOINT DATASET\n",
    "# In some rows, EntrezID, TaxaID & Name are the same -> Only SwissProt changes. We will group those rows\n",
    "\n",
    "# Remove all useless columns\n",
    "columns_to_keep = TFCheckpoint_exploded.columns.tolist()\n",
    "columns_to_remove = ['Entrez.Taxa.ID', 'Entrez.Gene.ID', 'UniProt.SwissProt.Accession', 'Ensembl.Gene.ID', 'UniProt', 'Ensembl']\n",
    "for column in columns_to_remove:\n",
    "    columns_to_keep.remove(column)\n",
    "\n",
    "# Group duplicated rows, with a | in between for UniProt & Ensembl.\n",
    "TFCheckpoint_exploded = TFCheckpoint_exploded.groupby(columns_to_keep, dropna=False).agg({\n",
    "    \"UniProt\": lambda x: \"|\".join(x),\n",
    "    \"Ensembl\": lambda x: \"|\".join(x)\n",
    "}).reset_index()\n",
    "\n",
    "# Display one example\n",
    "mask = TFCheckpoint_exploded[\"UniProt\"].str.contains(\"\\|\")\n",
    "md(f\"In {mask.sum()} TFs, one EntrezID is mapped to 2 different SwissProt Accession IDs. They have been joined by |. Example:\")\n",
    "display(HTML(TFCheckpoint_exploded[mask][:2][[\"Associated.Gene.Name\", \"Official name\", \"EntrezIDs\", \"TaxaIDs\", \"UniProt\", \"Ensembl\"]].to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# dbTF NCBI IDs in TFCheckpoint:  4390\n",
      "# coTF NCBI IDs in TFCheckpoint:  3598\n"
     ]
    }
   ],
   "source": [
    "# GET dbTF & coTF TFCHECKPONT GENE ID SETS\n",
    "TFCheckpoint_sets = {}\n",
    "for TF_type in [\"dbTF\", \"coTF\"]:\n",
    "    mask = TFCheckpoint_exploded[TFCheckpoint_cols[TF_type]].notna().any(axis=1)\n",
    "    TFCheckpoint_sets[TF_type] = set(TFCheckpoint_exploded[mask]['EntrezIDs'])\n",
    "    print(f\"# {TF_type} NCBI IDs in TFCheckpoint: {len(TFCheckpoint_sets[TF_type]):>5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final TF set for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We consider 9195 NCBI Gene IDs to be TFs\n"
     ]
    }
   ],
   "source": [
    "# Get TF sets from QuickGO & TFCheckpoint for each TF type\n",
    "TF_IDs_dict = {}\n",
    "for TF_type in [\"dbTF\", \"coTF\"]:\n",
    "    TF_IDs = set()\n",
    "\n",
    "    # Get QuickGO TFs\n",
    "    QuickGO_subset = QuickGO[QuickGO['TF type'] == TF_type]\n",
    "    QuickGO_IDs_set = {j for i in list(QuickGO_subset['TF ID']) for j in i}\n",
    "    \n",
    "    # Join QuickGO & TFCheckpoint TF sets & save to dictionary\n",
    "    TF_IDs_dict[TF_type] = QuickGO_IDs_set | TFCheckpoint_sets[TF_type]\n",
    "\n",
    "# Remove from the coTF set these GeneIDs present in the dbTF set\n",
    "TF_IDs_dict['coTF'].difference_update(TF_IDs_dict['dbTF'])\n",
    "\n",
    "# Add the less likely coTFs as a subset of the coTFs\n",
    "TF_IDs_dict['ll_coTF'] = ll_coTF.intersection(TF_IDs_dict['coTF'])\n",
    "\n",
    "# Save each of them as a list\n",
    "for TF_type in ['dbTF', 'coTF', 'll_coTF']:\n",
    "    path = get_TF_ids_path(TF_type, postprocessing_path)\n",
    "    with open(path, 'w') as f:\n",
    "        for TF in TF_IDs_dict[TF_type]:\n",
    "            f.write(TF + \"\\n\")\n",
    "\n",
    "# Combine all TFs & save them as a list\n",
    "all_TF_ids = TF_IDs_dict['dbTF'].union(TF_IDs_dict['coTF'])\n",
    "print(f\"We consider {len(all_TF_ids)} NCBI Gene IDs to be TFs\")\n",
    "\n",
    "with open(get_TF_ids_path('tf', postprocessing_path), 'w') as f:\n",
    "    for TF in all_TF_ids:\n",
    "        f.write(TF + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create final TF table\n",
    "Create TF table to use in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLS: ['lambert_2018.present', 'Lovering_2021.present', 'animal_tfdb_Homo_sapiens_cofactors.present', 'animal_tfdb_Mus_musculus_cofactors.present', 'animal_tfdb_Rattus_norvegicus_cofactors.present', 'tcof_cotf_human.present', 'tcof_cotf_mouse.present', 'TFclass_human', 'TFclass_mouse', 'TFclass_rat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene ID</th>\n",
       "      <th>original TF type</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>TaxID</th>\n",
       "      <th>GO:0003700</th>\n",
       "      <th>GO:0003712</th>\n",
       "      <th>GO:0001098</th>\n",
       "      <th>GO:0002039</th>\n",
       "      <th>GO:0008134</th>\n",
       "      <th>GO:0042393</th>\n",
       "      <th>GO:0046332</th>\n",
       "      <th>GO:0006325</th>\n",
       "      <th>GO:0140993</th>\n",
       "      <th>GO:0006355</th>\n",
       "      <th>lambert_2018.present</th>\n",
       "      <th>Lovering_2021.present</th>\n",
       "      <th>animal_tfdb_Homo_sapiens_cofactors.present</th>\n",
       "      <th>animal_tfdb_Mus_musculus_cofactors.present</th>\n",
       "      <th>animal_tfdb_Rattus_norvegicus_cofactors.present</th>\n",
       "      <th>tcof_cotf_human.present</th>\n",
       "      <th>tcof_cotf_mouse.present</th>\n",
       "      <th>TFclass_human</th>\n",
       "      <th>TFclass_mouse</th>\n",
       "      <th>TFclass_rat</th>\n",
       "      <th>updated TF type</th>\n",
       "      <th>human_gene_ID</th>\n",
       "      <th>human_symbol</th>\n",
       "      <th>hgnc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>54608</td>\n",
       "      <td>dbTF</td>\n",
       "      <td>Abhd2</td>\n",
       "      <td>10090</td>\n",
       "      <td>GO:0003707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GO:0003707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dbTF</td>\n",
       "      <td>11057</td>\n",
       "      <td>ABHD2</td>\n",
       "      <td>HGNC:18717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>11057</td>\n",
       "      <td>dbTF</td>\n",
       "      <td>ABHD2</td>\n",
       "      <td>9606</td>\n",
       "      <td>GO:0003707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GO:0003707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dbTF</td>\n",
       "      <td>11057</td>\n",
       "      <td>ABHD2</td>\n",
       "      <td>HGNC:18717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gene ID original TF type Symbol  TaxID  GO:0003700 GO:0003712 GO:0001098  \\\n",
       "63     54608             dbTF  Abhd2  10090  GO:0003707        NaN        NaN   \n",
       "1274   11057             dbTF  ABHD2   9606  GO:0003707        NaN        NaN   \n",
       "\n",
       "     GO:0002039 GO:0008134 GO:0042393 GO:0046332 GO:0006325 GO:0140993  \\\n",
       "63          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1274        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "      GO:0006355 lambert_2018.present Lovering_2021.present  \\\n",
       "63    GO:0003707                  NaN                   NaN   \n",
       "1274  GO:0003707                  NaN                   NaN   \n",
       "\n",
       "     animal_tfdb_Homo_sapiens_cofactors.present  \\\n",
       "63                                          NaN   \n",
       "1274                                        NaN   \n",
       "\n",
       "     animal_tfdb_Mus_musculus_cofactors.present  \\\n",
       "63                                          NaN   \n",
       "1274                                        NaN   \n",
       "\n",
       "     animal_tfdb_Rattus_norvegicus_cofactors.present tcof_cotf_human.present  \\\n",
       "63                                               NaN                     NaN   \n",
       "1274                                             NaN                     NaN   \n",
       "\n",
       "     tcof_cotf_mouse.present TFclass_human TFclass_mouse TFclass_rat  \\\n",
       "63                       NaN           NaN           NaN         NaN   \n",
       "1274                     NaN           NaN           NaN         NaN   \n",
       "\n",
       "     updated TF type human_gene_ID human_symbol     hgnc_id  \n",
       "63              dbTF         11057        ABHD2  HGNC:18717  \n",
       "1274            dbTF         11057        ABHD2  HGNC:18717  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "updated TF type\n",
       "dbTF              4163\n",
       "coTF candidate    3573\n",
       "coTF               933\n",
       "                   528\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>updated TF type</th>\n",
       "      <th>dbTF</th>\n",
       "      <th>coTF</th>\n",
       "      <th>coTF candidate</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GO:0006355</th>\n",
       "      <td>3062</td>\n",
       "      <td>914</td>\n",
       "      <td>1657</td>\n",
       "      <td>5633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0003700</th>\n",
       "      <td>2646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0006325</th>\n",
       "      <td>349</td>\n",
       "      <td>271</td>\n",
       "      <td>1168</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0008134</th>\n",
       "      <td>609</td>\n",
       "      <td>327</td>\n",
       "      <td>484</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0003712</th>\n",
       "      <td>209</td>\n",
       "      <td>933</td>\n",
       "      <td>0</td>\n",
       "      <td>1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0140993</th>\n",
       "      <td>88</td>\n",
       "      <td>113</td>\n",
       "      <td>268</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0042393</th>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "      <td>269</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0046332</th>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>92</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0002039</th>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>92</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0001098</th>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>95</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "updated TF type  dbTF  coTF  coTF candidate  Total\n",
       "GO term                                           \n",
       "GO:0006355       3062   914            1657   5633\n",
       "GO:0003700       2646     0               0   2646\n",
       "GO:0006325        349   271            1168   1788\n",
       "GO:0008134        609   327             484   1420\n",
       "GO:0003712        209   933               0   1142\n",
       "GO:0140993         88   113             268    469\n",
       "GO:0042393         42    54             269    365\n",
       "GO:0046332         74    30              92    196\n",
       "GO:0002039         20    41              92    153\n",
       "GO:0001098         28    19              95    142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join all TF IDs into one dataframe\n",
    "TFs_list = []\n",
    "for TF in ['dbTF', 'coTF', 'll_coTF']:\n",
    "    path = get_TF_ids_path(TF, postprocessing_path) \n",
    "    with open(path, 'r') as f:\n",
    "        all_gene_IDs = f.read().splitlines()\n",
    "        TFs_list.extend([(gene_id, TF) for gene_id in all_gene_IDs])\n",
    "TFs_df = pd.DataFrame(TFs_list, columns=[\"Gene ID\", \"TF type\"])\n",
    "\n",
    "# Drop coTFs that are also ll_coTFs\n",
    "coTFs_set = set(TFs_df[TFs_df['TF type'] == 'coTF']['Gene ID'])\n",
    "TFs_df = TFs_df[~((TFs_df['TF type'] == 'coTF') & (TFs_df['Gene ID'].isin(ll_coTF)))]\n",
    "assert len(TFs_df) == len(set(TFs_df['Gene ID'])), \"There are duplicated Gene IDs in the TFs_df\"\n",
    "\n",
    "# Use eutils to map each gene ID to the gene symbol & TF type\n",
    "annotationsSummary = retrieve_annotations_entrez(TFs_df['Gene ID'].tolist())\n",
    "EntrezIDtoSymbol = {ID : {'Name': annotation[\"Name\"], 'TaxID': annotation['Organism']['TaxID']} for ID, annotation in zip(TFs_df['Gene ID'].tolist(), annotationsSummary)}\n",
    "TFs_df['Symbol'] = TFs_df['Gene ID'].map(lambda ID: EntrezIDtoSymbol[ID]['Name'])\n",
    "TFs_df['TaxID'] = TFs_df['Gene ID'].map(lambda ID: EntrezIDtoSymbol[ID]['TaxID'])\n",
    "\n",
    "\n",
    "# --- JOIN WITH QUICKGO ---\n",
    "for GO_term in GO_dbTF + GO_coTF + [\"GO:0006355\"]:\n",
    "    # Load the GO term table\n",
    "    GO_table = pd.read_csv(external_data_path + f\"QuickGO-{GO_term.replace(':', '')}.tsv\", sep=\"\\t\", header=0, dtype='str')\n",
    "\n",
    "    # Process the GO term table\n",
    "    GO_table = (\n",
    "        GO_table[['SYMBOL', 'TAXON ID', 'GO TERM']].drop_duplicates()\n",
    "        .groupby([\"SYMBOL\", \"TAXON ID\"], as_index=False)\n",
    "        .agg({\"GO TERM\": lambda x: \";\".join(sorted(set(x.dropna().astype(str))))})\n",
    "        .rename(columns={\"GO TERM\": GO_term})\n",
    "    )\n",
    "\n",
    "    # Merge with TFs_df\n",
    "    TFs_df = TFs_df.merge(GO_table, left_on=['Symbol', 'TaxID'], right_on=['SYMBOL', 'TAXON ID'], how='left').drop(columns=[\"TAXON ID\", \"SYMBOL\"])\n",
    "\n",
    "\n",
    "# --- JOIN WITH TFCHECKPOINT ---\n",
    "# Join together duplicated rows in TFCheckpoint\n",
    "cols = [col for cols in TFCheckpoint_cols.values() for col in cols if ((\"GO:\" not in col) & (col != 'TFclass.present.merged'))] + ['TFclass_human', 'TFclass_mouse', 'TFclass_rat'] # Only include relevant columns\n",
    "print(\"COLS:\", cols)\n",
    "TFCheckpoint_agg = (\n",
    "    TFCheckpoint_exploded[['EntrezIDs'] + cols]\n",
    "    .groupby('EntrezIDs', as_index=False)\n",
    "    .agg({\n",
    "        c: (lambda x: \";\".join(sorted(set(x.dropna().astype(str)))))\n",
    "        for c in cols\n",
    "    })\n",
    ")\n",
    "\n",
    "# Merge with TFCheckpoint\n",
    "TFs_df = TFs_df.merge(TFCheckpoint_agg[cols + ['EntrezIDs']], left_on=['Gene ID'], right_on=['EntrezIDs'], how='left').drop(columns=[\"EntrezIDs\"])\n",
    "\n",
    "# Ensure sources only have values for the correct species\n",
    "TFs_df.loc[TFs_df['TaxID'] != '9606',  ['TFclass_human', 'animal_tfdb_Homo_sapiens_cofactors.present', 'tcof_cotf_human.present', 'lambert_2018.present', 'Lovering_2021.present']] = np.nan\n",
    "TFs_df.loc[TFs_df['TaxID'] != '10090', ['TFclass_mouse', 'animal_tfdb_Mus_musculus_cofactors.present', 'tcof_cotf_mouse.present']] = np.nan\n",
    "TFs_df.loc[TFs_df['TaxID'] != '10116', ['TFclass_rat',   'animal_tfdb_Rattus_norvegicus_cofactors.present']] = np.nan\n",
    "\n",
    "# --- CREATE NEW TF CATEGORISATION ---\n",
    "new_categorisation_cols = {\n",
    "    'dbTF': GO_dbTF + [col for col in TFCheckpoint_cols['dbTF'] if col not in ['TFclass.present.merged']] + ['TFclass_human', 'TFclass_mouse', 'TFclass_rat'],\n",
    "    'coTF candidate': GO_coTF + TFCheckpoint_cols['coTF'] + [\"GO:0006355\"],\n",
    "    'coTF': [\"GO:0003712\"]\n",
    "}\n",
    "\n",
    "TFs_df = TFs_df.replace(\"\", np.nan) # Replace empty strings with NaN\n",
    "TFs_df[\"updated TF type\"] = '' # Default\n",
    "# dbTF will overwrite coTF, which will overwrite coTF candidate\n",
    "for tf_type in ['coTF candidate', 'coTF', 'dbTF']:\n",
    "    cols = new_categorisation_cols[tf_type]\n",
    "    TFs_df.loc[TFs_df[cols].notna().any(axis=1), 'updated TF type'] = tf_type\n",
    "\n",
    "# --- ADD NFKB & AP1 COMPLEXES ---\n",
    "TFs_df = pd.concat([TFs_df, pd.DataFrame([{\n",
    "    'Gene ID': f\"Complex:{complex}\",\n",
    "    'Symbol': complex,\n",
    "    'TF type': \"dbTF\",\n",
    "    'updated TF type': \"dbTF\",\n",
    "} for complex in ['AP1', 'NFKB']])], ignore_index=True)\n",
    "\n",
    "# Change TF_type by \"original TF type\"\n",
    "TFs_df.rename(columns={\"TF type\": \"original TF type\"}, inplace=True)\n",
    "\n",
    "# --- ADD ORTHOLOGS INFORMATION ---\n",
    "all_orthologs_df = pd.read_csv(all_orthologs_path, sep=\"\\t\", dtype='str').set_index('Gene_ID')\n",
    "TFs_df['human_gene_ID']     = TFs_df['Gene ID'].map(all_orthologs_df['unique_human_gene_ID'])\n",
    "TFs_df['human_symbol']      = TFs_df['Gene ID'].map(all_orthologs_df['unique_human_gene_symbol'])\n",
    "TFs_df['hgnc_id']           = TFs_df['Gene ID'].map(all_orthologs_df['unique_HGNC_ID'])\n",
    "\n",
    "# Ensure all human TFs have the \"human\" columns filled in (some are not in the Ensembl orthologs list)\n",
    "m_human = TFs_df['TaxID'] == '9606'\n",
    "TFs_df.loc[m_human, 'human_gene_ID'] = TFs_df.loc[m_human, 'Gene ID']\n",
    "TFs_df.loc[m_human, 'human_symbol']  = TFs_df.loc[m_human, 'Symbol']\n",
    "\n",
    "# Assertions\n",
    "assert len(TFs_df) == len(set(TFs_df['Gene ID'])), \"There are duplicated Gene IDs in the TFs_df\"\n",
    "\n",
    "# -- CLEAN UP & SAVE ---\n",
    "# Sort rows\n",
    "order = [\"dbTF\", \"coTF\", \"coTF candidate\", \"\"]\n",
    "TFs_df[\"updated TF type\"] = pd.Categorical(TFs_df[\"updated TF type\"], categories=order, ordered=True)\n",
    "TFs_df = TFs_df.sort_values(by=['updated TF type', 'human_symbol', 'TaxID'], ascending=[True, True, True])\n",
    "\n",
    "# Save the complete dataset\n",
    "TFs_df.to_csv(all_TFs_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# --- SHOW STATS ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(TFs_df.head(2))\n",
    "display(TFs_df['updated TF type'].value_counts(dropna=False))\n",
    "\n",
    "# Show updated TF types per GO term\n",
    "summary = (\n",
    "    TFs_df\n",
    "    .melt(id_vars=\"updated TF type\", value_vars=[c for c in TFs_df.columns if c.startswith(\"GO:\")],\n",
    "          var_name=\"GO term\", value_name=\"present\")\n",
    "    .assign(present=lambda d: d[\"present\"].notna())\n",
    "    .query(\"present == True\")\n",
    "    .groupby([\"GO term\", \"updated TF type\"], observed=True)\n",
    "    .size()\n",
    "    .unstack(fill_value=0)       # columns = updated TF type\n",
    ")\n",
    "summary[\"Total\"] = summary.sum(axis=1)\n",
    "display(summary.sort_values(\"Total\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique GO:0006355 entries: 7338\n",
      "Number considered: 5633\n"
     ]
    }
   ],
   "source": [
    "# Check how many GO:0006355 we retrieve\n",
    "GO_term = \"GO:0006355\"\n",
    "\n",
    "# Process the GO term table\n",
    "GO_table = pd.read_csv(external_data_path + f\"QuickGO-{GO_term.replace(':', '')}.tsv\", sep=\"\\t\", header=0, dtype='str')\n",
    "\n",
    "GO_table = (\n",
    "    GO_table[['SYMBOL', 'TAXON ID', 'GO TERM']].drop_duplicates()\n",
    "    .groupby([\"SYMBOL\", \"TAXON ID\"], as_index=False)\n",
    "    .agg({\"GO TERM\": lambda x: \";\".join(sorted(set(x.dropna().astype(str))))})\n",
    "    .rename(columns={\"GO TERM\": GO_term})\n",
    ")\n",
    "\n",
    "print(f\"Unique {GO_term} entries: {GO_table.shape[0]}\")\n",
    "print(f\"Number considered: {TFs_df[GO_term].notna().sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
