{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2058b1-bd55-4fe4-9293-4fd0ab2de790",
   "metadata": {},
   "source": [
    "# Create training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e9b57-bf8f-4f70-9034-675c6448dcb7",
   "metadata": {},
   "source": [
    "This notebook creates the datasets used to train the TRI and MoR classifiers. It must be run after `update_tri_sentences.ipynb` which updates the original dataset with the reannotated sentences.\n",
    "\n",
    "Using the raw dataset `tri_sentences.tsv`, 4 datasets are created:\n",
    "* `TRI_data`\n",
    "* `TRI_span_data`\n",
    "* `MoR_data`\n",
    "* `MoR_span_data`\n",
    "\n",
    "Where:\n",
    "* In `TRI_data` and `MoR_data`, the TF and TG entities are masked by the `[TF]` and `[TG]` tokens.\n",
    "* `_span` indicates that the TF and TG are enclosed into `<TF></TF>`, `<TG></TG>` tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ec0f3-29a3-4ae0-aff8-eb57d8b9cea5",
   "metadata": {},
   "source": [
    "## Imports and general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a078d3e3-43b9-4240-b2d9-b9a2a9b437d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.display import display, HTML, display_html\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# My functions\n",
    "import sys\n",
    "sys.path.append('../common/') \n",
    "from analysis_utils import prettify_plots\n",
    "from notebook_utils import table_of_contents, table_from_dict\n",
    "\n",
    "prettify_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a52785f7-e197-4b27-b722-d4cdcfcd7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define general functions\n",
    "def plot_dataset_data(data, ax, title, bins):\n",
    "    list1 = data[data['Label'] == 1 ]['Text'].apply(len)\n",
    "    list0 = data[data['Label'] == 0 ]['Text'].apply(len)\n",
    "    ax.hist(list0, bins=bins[0], edgecolor='k', color= 'red', alpha=0.5)\n",
    "    ax.hist(list1, bins=bins[1], edgecolor='k', color= 'green', alpha=0.5)\n",
    "    #ax.hist([list0, list1], bins=bins[0], edgecolor='k', color=['red', 'green'], alpha=1, label=['DISCARDED', 'ACCEPTED'], stacked=False)\n",
    "\n",
    "    ax.set_xlabel('Sequence Length')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    suptitle = f\"{len(data[data['Label'] == 1])} positives ({len(data[data['Label'] == 1])/len(data)*100:.2f}%)\"\n",
    "    ax.set_title(f\"{title}\\n{suptitle}\")  \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "183a0c3a-9f12-43ab-baff-910a7cc6e5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3>Table of contents</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Create training data](#Create-training-data)\n",
       "- [Imports and general functions](#Imports-and-general-functions)\n",
       "- [Paths & Load data](#Paths-&-Load-data)\n",
       "- [Create training datasets](#Create-training-datasets)\n",
       "  - [TRI & MoR spans](#TRI-&-MoR-spans)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_of_contents('make_train_data.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9015e-703a-48fb-9c65-d3789a38e7e4",
   "metadata": {},
   "source": [
    "## Paths & Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0f68562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "# Input paths\n",
    "classifiers_data_path = '../../classifiers_training/data/'\n",
    "TRI_data_path  = classifiers_data_path + 'tri_sentences.tsv'\n",
    "\n",
    "# Output paths\n",
    "output_path = classifiers_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dce1a8bf-e704-4f71-8738-5a241cc8ff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRI dataset"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#TRI ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>TF</th>\n",
       "      <th>TG</th>\n",
       "      <th>Label</th>\n",
       "      <th>Type</th>\n",
       "      <th>validated?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>11274170:0:PEA3:Wnt1</td>\n",
       "      <td>Therefore, we speculate that [TF] factors may contribute to the up-regulation of COX-2 expression resulting from both APC mutation and [TG] expression.</td>\n",
       "      <td>PEA3</td>\n",
       "      <td>Wnt1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>11274170:0:PEA3:cyclooxygenase-2</td>\n",
       "      <td>[TF] is up-regulated in response to Wnt1 and activates the expression of [TG].</td>\n",
       "      <td>PEA3</td>\n",
       "      <td>cyclooxygenase-2</td>\n",
       "      <td>True</td>\n",
       "      <td>ACTIVATION</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                           #TRI ID  \\\n",
       "51          51              11274170:0:PEA3:Wnt1   \n",
       "52          52  11274170:0:PEA3:cyclooxygenase-2   \n",
       "\n",
       "                                                                                                                                                   Sentence  \\\n",
       "51  Therefore, we speculate that [TF] factors may contribute to the up-regulation of COX-2 expression resulting from both APC mutation and [TG] expression.   \n",
       "52                                                                           [TF] is up-regulated in response to Wnt1 and activates the expression of [TG].   \n",
       "\n",
       "      TF                TG  Label        Type  validated?  \n",
       "51  PEA3              Wnt1  False         NaN       False  \n",
       "52  PEA3  cyclooxygenase-2   True  ACTIVATION       False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "TRI_data = pd.read_csv(TRI_data_path,sep='\\t', header=0)\n",
    "\n",
    "# Show data\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "display(HTML('TRI dataset'))\n",
    "TRI_data[51:53]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7826ff3f-7701-4529-86be-26f894d528ac",
   "metadata": {},
   "source": [
    "## Create training datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858c9e8-883c-4726-b128-3a1f7e540d99",
   "metadata": {},
   "source": [
    "Both sentences and MoR data come from the same source: `raw_data/tri_sentences.tsv` (modified from the original `raw_data/original_tri_sentences.tsv` in the notebook `update_raw_data.ipynb`)\n",
    "\n",
    "For the **TRI classifier**, two datasets are created: the original and a masked one, where all the genes are masked by the token `[G]`.\n",
    "\n",
    "For the **MoR classifier**, the dataset has 3 labels: `UNDEFINED`, `ACTIVATION` and `REPRESSION`. Those labels are changed, respectively, by the numbers 0, 1 and 2. This is specified into the model in the following way:\n",
    "\n",
    "- `id2label = {0: \"UNDEFINED\", 1: \"ACTIVATION\", 2: \"REPRESSION\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feb896c6-9518-49bb-9113-340b22571ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for the TRI sentences:\n",
      "    total:\t\t22160\n",
      "    positives:\t\t11695\n",
      "    negatives:\t\t10465\n",
      "\n",
      "For the positive sentences, number of MoR of each category:\n",
      "UNDEFINED\t4149\n",
      "ACTIVATION\t5489\n",
      "REPRESSION\t2057\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "# Change labels from booleans to 0 and 1\n",
    "TRI_data['Label'] = TRI_data['Label'].astype(int)\n",
    "# Get the MoR data\n",
    "MoR_data = TRI_data[TRI_data['Label'] == 1]\n",
    "\n",
    "# Show some statistics of the data\n",
    "print(f'''Stats for the TRI sentences:\n",
    "    total:\\t\\t{len(TRI_data)}\n",
    "    positives:\\t\\t{len(TRI_data[TRI_data['Label'] == 1])}\n",
    "    negatives:\\t\\t{len(TRI_data[TRI_data['Label'] == 0])}\n",
    "\n",
    "For the positive sentences, number of MoR of each category:''')\n",
    "for MoR_type in MoR_data['Type'].unique():\n",
    "    print(f'{MoR_type}\\t{len(TRI_data[TRI_data[\"Type\"] == MoR_type])}')\n",
    "\n",
    "# Change the labels for numbers\n",
    "MoR_data.loc[MoR_data['Type'] == 'UNDEFINED',  'Label'] = 0\n",
    "MoR_data.loc[MoR_data['Type'] == 'ACTIVATION', 'Label'] = 1\n",
    "MoR_data.loc[MoR_data['Type'] == 'REPRESSION', 'Label'] = 2\n",
    "\n",
    "# Change to names expected by pytorch\n",
    "TRI_data = TRI_data.rename(columns={'Label': 'labels', 'Sentence': 'texts'})\n",
    "MoR_data = MoR_data.rename(columns={'Label': 'labels', 'Sentence': 'texts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08f5cc0a-1ed3-4243-9a20-b2fe7e07c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets\n",
    "TRI_data.to_csv(output_path + 'TRI_data.tsv', sep='\\t')\n",
    "MoR_data.to_csv(output_path + 'MoR_data.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78163b2-ab27-48ce-ade1-183c61481b56",
   "metadata": {},
   "source": [
    "### TRI & MoR spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972a2e4-c62e-4b2e-950b-47bfa8cc2044",
   "metadata": {},
   "source": [
    "Using `[TF]`, `[TG]`, the model looses all information on what that TF and TG is. This could hinder the model: in the (frequent) cases where the TF or TG is mentioned twice in the sentence, the model can't know the token refers to that other one in the sentence.\n",
    "\n",
    "Therefore, we will also train the model with datasets that contain spans `<TF></TF>` and `<TG></TG>` instead of `[TF]` and `[TG]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7d8bfa2-ca1c-47a6-aa6b-0076ebe8615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify [TF] by <TF>...</TF> in both TRI and MoR\n",
    "TRI_span_data = TRI_data.copy()\n",
    "MoR_span_data = MoR_data.copy()\n",
    "\n",
    "TRI_span_data['texts'] = TRI_span_data.apply(lambda row: row['texts'].replace('[TF]', f\"<TF>{row['TF']}</TF>\").replace('[TG]', f\"<TG>{row['TG']}</TG>\"), axis=1)\n",
    "MoR_span_data['texts'] = MoR_span_data.apply(lambda row: row['texts'].replace('[TF]', f\"<TF>{row['TF']}</TF>\").replace('[TG]', f\"<TG>{row['TG']}</TG>\"), axis=1)\n",
    "\n",
    "# Save the datasets\n",
    "TRI_span_data.to_csv(output_path + 'TRI_span_data.tsv', sep='\\t')\n",
    "MoR_span_data.to_csv(output_path + 'MoR_span_data.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".general_env",
   "language": "python",
   "name": ".general_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
