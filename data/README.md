# Overview
This folder contains all original and intermediate datasets required for creating the final ExTRI2 dataset, except for those used for classifiers training (found in `classifiers_training/`), so that classifier training can be done independently from the rest.

# Structure
- `pubtator/` contains the abstracts used in `workflow.rb`, along with their Gene annotations.
- `tf_entrez_code.list` has a list of all IDs considered as TFs by the ExTRI2 pipeline.
- `external/` saves all datasets that come from outside ExTRI: ortholog lists, TF IDs, and the original training dataset.
- `dataset_improvement/` contains the reannotated .tsv files used to improve the training dataset, generated by `scripts/classifiers_training/prepare_reannotation_Excels.ipynb`
- `postprocessing/` saves datasets used for, or resulting from, the `scripts/postprocessing/postprocessing.py` script.
- `validation/` saves the .tsv files used to validate the ExTRI2 results, before and after validation.


- [ ] Detail more how did I obtain each dataset. What script did I run / which website did I download it from?
  - [ ] Ensure the `external` explanation below is completed (pretty sure it isn't)
- [ ] Think more of how to structure the part below. What is relevant to explain further, and what can be found in the paper?

## Obtention of `external/` datasets
### human_HGNC_orthologs
This folder contains 3 tsv files with orthology mappings between mouse, rat and human. 

human_mouse & human_rat mappings were obtained from https://www.genenames.org/tools/hcop/. From there, I downloaded (01/07/2024):
* human - mouse ortholog data as a 15 column tab delimited text file
* human - rat ortholog data as a 15 column tab delimited text file
hgnc_human was downloaded from https://www.genenames.org/download/custom/ (25/08/2024) to get the HGNC IDs from human NCBI IDs

### TF_id
- [ ] Explain how I obtained the QuickGO & TFCheckpoint annotations

### tsv files
* `original_tri_sentences.tsv` is the original tsv file that was used for training the classifiers (see `classifiers_training/`)
* `NTNU_extended.tsv` is where `original_tri_sentences.tsv` comes from, after applying a group of filters
* `all_human_TGs.tsv` contains all human genes, including protein-coding, small RNAs, pseudogenes & non-coding. Used for analysis. Downloaded from https://www.ncbi.nlm.nih.gov/datasets/gene/taxon/9606/ on 15/11/2024 

- [ ] Should we explain the filters used to obtain the original_train_sentences? We didn't use them all and should explain why right?